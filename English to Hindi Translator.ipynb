{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c97bb70",
   "metadata": {},
   "source": [
    "### English to Hindi Translation using Transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41c5e3",
   "metadata": {},
   "source": [
    "Abstract: \n",
    "In our project aimed at translating English literature into Hindi using transformers, we delved into the intricacies of this state-of-the-art architecture. Transformers revolutionize natural language processing through their self-attention mechanism, enabling better understanding of long-range dependencies crucial for tasks like translation. Comprising encoder and decoder components, transformers process input text, generate hidden representations, and produce translated outputs. Positional encoding preserves sequence order, essential in a non-sequential architecture. Training on English-Hindi sentence pairs refined our model's ability to capture language nuances. This project deepened our grasp of encoder-decoder architecture, self-attention, positional encoding, and the transformative potential of transformers in machine learning endeavors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35974013",
   "metadata": {},
   "source": [
    "#### We shall import the necessary libraries now, we will be using tensorflow for some heavy lifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bcf78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6f2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_LEN = 100\n",
    "DECODER_LEN = 100\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = BATCH_SIZE*4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b3d32",
   "metadata": {},
   "source": [
    "Constants crucial for training a machine translation model, likely using an architecture such as a transformer\n",
    "\n",
    "Let us see what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb388c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63241</th>\n",
       "      <td>Indian News Service - National News Agency</td>\n",
       "      <td>इण्डियन न्यूज सर्विस - राष्ट्रीय समाचार एजेंसी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>In West Bengal , it seems set to eat humble pi...</td>\n",
       "      <td>पश्चिम बंगाल में तो वह अपमान का घूंट पीने को भ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>One american dollar is equal to 60 pakistani r...</td>\n",
       "      <td>एक अमरीकी डालर की कीमत लगभग ६० पाकिस्तानी रुपय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73434</th>\n",
       "      <td>but between those high highs,</td>\n",
       "      <td>लेकिन इन बेहतरीन लम्हों के बीच</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65711</th>\n",
       "      <td>Every other politician went along because when...</td>\n",
       "      <td>और वजह यह थी कि आर्थिक मामलं पर हमेशा विफल विच...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        english_sentence  \\\n",
       "63241         Indian News Service - National News Agency   \n",
       "81404  In West Bengal , it seems set to eat humble pi...   \n",
       "8803   One american dollar is equal to 60 pakistani r...   \n",
       "73434                      but between those high highs,   \n",
       "65711  Every other politician went along because when...   \n",
       "\n",
       "                                          hindi_sentence  \n",
       "63241     इण्डियन न्यूज सर्विस - राष्ट्रीय समाचार एजेंसी  \n",
       "81404  पश्चिम बंगाल में तो वह अपमान का घूंट पीने को भ...  \n",
       "8803   एक अमरीकी डालर की कीमत लगभग ६० पाकिस्तानी रुपय...  \n",
       "73434                     लेकिन इन बेहतरीन लम्हों के बीच  \n",
       "65711  और वजह यह थी कि आर्थिक मामलं पर हमेशा विफल विच...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/Users/meghnahavalgi/Desktop/Neural Modelling/Hindi_English_Truncated_Corpus.csv\")\n",
    "train_df.drop(['source'],axis=1,inplace=True)\n",
    "mask = (train_df['english_sentence'].str.len()>20) & (train_df['english_sentence'].str.len()<200)\n",
    "train_df = train_df.loc[mask]\n",
    "train_df = train_df.sample(64000, random_state=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a858326",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ec4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = train_df['english_sentence']\n",
    "hind = train_df['hindi_sentence']\n",
    "eng = eng.apply(lambda x: \"<SOS> \" + str(x) + \" <EOS>\")\n",
    "hind = hind.apply(lambda x: \"<SOS> \"+ x + \" <EOS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a7e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'\n",
    "eng_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = filters, oov_token=oov_token)\n",
    "hind_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = filters, oov_token=oov_token)\n",
    "eng_tokenizer.fit_on_texts(eng)\n",
    "hind_tokenizer.fit_on_texts(hind)\n",
    "inputs = eng_tokenizer.texts_to_sequences(eng)\n",
    "targets = hind_tokenizer.texts_to_sequences(hind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1482712",
   "metadata": {},
   "source": [
    "We preprocess the input English and Hindi texts, tokenize them, and convert them into sequences of word indices for further processing in the machine translation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7187583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44305 51960\n"
     ]
    }
   ],
   "source": [
    "ENCODER_VOCAB = len(eng_tokenizer.word_index) + 1\n",
    "DECODER_VOCAB = len(hind_tokenizer.word_index) + 1\n",
    "print(ENCODER_VOCAB, DECODER_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e73cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\n",
    "inputs = tf.cast(inputs, dtype=tf.int64)\n",
    "targets = tf.cast(targets, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db51ad2",
   "metadata": {},
   "source": [
    "These preprocessing steps standardize the lengths of input and target sequences, making them suitable for training the machine translation model. Padding ensures that shorter sequences match the maximum sequence length, while truncating ensures longer sequences are trimmed to fit within the specified length constraints. Finally, casting the sequences to integers prepares them for consumption by the TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee802f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8fcdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4aa70",
   "metadata": {},
   "source": [
    "Following are the important functions and their brief describtion of them, why is it important is also something that we need to think of,\n",
    "- get_angles(position, i, d_model) : Calculates the angles used in positional encoding.\n",
    "- positional_encoding(position, d_model) : Computes the positional encoding matrix for a given position and model dimension\n",
    "- create_padding_mask(seq) : Creates a mask to mark padding tokens in a sequence.\n",
    "- create_look_ahead_mask(size) ; Creates a mask to prevent attention scores from considering future tokens.\n",
    "- scaled_dot_product_attention(q, k, v, mask) - Computes scaled dot-product attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245c1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dafc079",
   "metadata": {},
   "source": [
    "These components are fundamental building blocks of the transformer model. The multi-head attention mechanism enables the model to focus on different parts of the input sequence simultaneously, while the point-wise feed-forward network introduces non-linearity and enhances the model's expressiveness, crucial for capturing complex patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff55eb",
   "metadata": {},
   "source": [
    "#### Whats Encoder and Decoder ? \n",
    "Encoders and Decoders are the backbone of tranformers.\n",
    "\n",
    "In my understanding, encoder processes the input sequence to create a contextual representation that captures the relevant information for the task at hand and Decoder takes the contextual representation generated by the encoder and uses it to generate the output sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a79c83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4484484",
   "metadata": {},
   "source": [
    "self-attention (MultiHeadAttention) and feed-forward network (point_wise_feed_forward_network) layers are applied to the input sequence.\n",
    "self-attention helps the encoder understand the relationships between different words in the input sequence.\n",
    "The feed-forward network introduces non-linearity and enhances the model's expressiveness.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e78ddeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d58bb4",
   "metadata": {},
   "source": [
    "decoder also consists of self-attention mechanisms (mha1 and mha2) and a feed-forward network (ffn).\n",
    "The first self-attention mechanism (mha1) helps the decoder focus on relevant parts of the input sequence during the decoding process.\n",
    "The second self-attention mechanism (mha2) allows the decoder to attend to both the input sequence and its own generated output, facilitating the generation of coherent and contextually relevant translations.\n",
    "\n",
    "\n",
    "We repeat introducing encoder and decoder to make the model much more familier with the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "485f0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "        \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463b7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bfe06e",
   "metadata": {},
   "source": [
    "Transformer class integrates both the encoder and decoder components of the transformer architecture.\n",
    "By combining the encoder (self.encoder) and decoder (self.decoder) within the same class, the model structure is encapsulated, making it easier to manage and manipulate the entire transformer architecture as a single entity.\n",
    "\n",
    "it also includes a final dense layer (self.final_layer) after the decoder.\n",
    "By applying a dense layer, the model learns to produce the probability distribution over the target vocabulary, facilitating the generation of meaningful predictions.\n",
    "\n",
    "call method of the Transformer class implements the forward pass of the transformer model.It returns the final output sequence and attention weights, allowing for both training and inference with the transformer model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b005ab6",
   "metadata": {},
   "source": [
    "Since we have the model architecture set up, lets train the model considering the following parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58bd3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6122b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "32af1474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8d8b7",
   "metadata": {},
   "source": [
    "We need a graph visualizes how the learning rate changes over the course of training, providing insights into the optimization process and helping optimize the training hyperparameters for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74c31a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975b6de",
   "metadata": {},
   "source": [
    "we can see at 5000th train step, our learning rate is high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582d02a",
   "metadata": {},
   "source": [
    "Going forward we would want to compute loss computation, accuracy calculation, and checkpoint management to facilitate efficient model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2f95b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4274e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c10f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=ENCODER_VOCAB,\n",
    "    target_vocab_size=DECODER_VOCAB,\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64df1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74b96fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "064015c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6d53d",
   "metadata": {},
   "source": [
    "train_step function encapsulates the entire training process for a single batch of data, including forward pass, loss computation, gradient calculation, parameter updates, and metric tracking, making it a fundamental component of the training loop for the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "833cc19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 10.8595 Accuracy 0.0000\n",
      "Epoch 1 Batch 200 Loss 10.5004 Accuracy 0.0460\n",
      "Epoch 1 Batch 400 Loss 9.6690 Accuracy 0.0534\n",
      "Epoch 1 Batch 600 Loss 8.9343 Accuracy 0.0567\n",
      "Epoch 1 Batch 800 Loss 8.4781 Accuracy 0.0658\n",
      "Epoch 1 Loss 8.1439 Accuracy 0.0757\n",
      "Time taken for 1 epoch: 3506.23331618309 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 6.7417 Accuracy 0.0758\n",
      "Epoch 2 Batch 200 Loss 6.6002 Accuracy 0.0848\n",
      "Epoch 2 Batch 400 Loss 6.5222 Accuracy 0.0928\n",
      "Epoch 2 Batch 600 Loss 6.4472 Accuracy 0.0999\n",
      "Epoch 2 Batch 800 Loss 6.3773 Accuracy 0.1063\n",
      "Epoch 2 Loss 6.3140 Accuracy 0.1121\n",
      "Time taken for 1 epoch: 19303.365352869034 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 6.0962 Accuracy 0.1121\n",
      "Epoch 3 Batch 200 Loss 5.9493 Accuracy 0.1176\n",
      "Epoch 3 Batch 400 Loss 5.8965 Accuracy 0.1226\n",
      "Epoch 3 Batch 600 Loss 5.8459 Accuracy 0.1276\n",
      "Epoch 3 Batch 800 Loss 5.7982 Accuracy 0.1322\n",
      "Epoch 3 Loss 5.7526 Accuracy 0.1365\n",
      "Time taken for 1 epoch: 14694.372776985168 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 5.5772 Accuracy 0.1365\n",
      "Epoch 4 Batch 200 Loss 5.4850 Accuracy 0.1407\n",
      "Epoch 4 Batch 400 Loss 5.4436 Accuracy 0.1446\n",
      "Epoch 4 Batch 600 Loss 5.4013 Accuracy 0.1485\n",
      "Epoch 4 Batch 800 Loss 5.3627 Accuracy 0.1522\n",
      "Epoch 4 Loss 5.3279 Accuracy 0.1557\n",
      "Time taken for 1 epoch: 4020.668342113495 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 5.1677 Accuracy 0.1557\n",
      "Epoch 5 Batch 200 Loss 5.1123 Accuracy 0.1592\n",
      "Epoch 5 Batch 400 Loss 5.0657 Accuracy 0.1626\n",
      "Epoch 5 Batch 600 Loss 5.0195 Accuracy 0.1661\n",
      "Epoch 5 Batch 800 Loss 4.9772 Accuracy 0.1695\n",
      "Saving checkpoint for epoch 5 at checkpoints/ckpt-1\n",
      "Epoch 5 Loss 4.9367 Accuracy 0.1729\n",
      "Time taken for 1 epoch: 5901.180130958557 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 4.7429 Accuracy 0.1729\n",
      "Epoch 6 Batch 200 Loss 4.6971 Accuracy 0.1764\n",
      "Epoch 6 Batch 400 Loss 4.6676 Accuracy 0.1798\n",
      "Epoch 6 Batch 600 Loss 4.6291 Accuracy 0.1832\n",
      "Epoch 6 Batch 800 Loss 4.5980 Accuracy 0.1865\n",
      "Epoch 6 Loss 4.5676 Accuracy 0.1898\n",
      "Time taken for 1 epoch: 3350.9397959709167 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 4.4257 Accuracy 0.1898\n",
      "Epoch 7 Batch 200 Loss 4.3962 Accuracy 0.1932\n",
      "Epoch 7 Batch 400 Loss 4.3719 Accuracy 0.1964\n",
      "Epoch 7 Batch 600 Loss 4.3384 Accuracy 0.1997\n",
      "Epoch 7 Batch 800 Loss 4.3155 Accuracy 0.2029\n",
      "Epoch 7 Loss 4.2934 Accuracy 0.2061\n",
      "Time taken for 1 epoch: 3492.952893972397 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 4.2876 Accuracy 0.2061\n",
      "Epoch 8 Batch 200 Loss 4.1585 Accuracy 0.2092\n",
      "Epoch 8 Batch 400 Loss 4.1370 Accuracy 0.2123\n",
      "Epoch 8 Batch 600 Loss 4.1116 Accuracy 0.2155\n",
      "Epoch 8 Batch 800 Loss 4.0954 Accuracy 0.2185\n",
      "Epoch 8 Loss 4.0785 Accuracy 0.2215\n",
      "Time taken for 1 epoch: 4796.367094039917 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 4.0830 Accuracy 0.2215\n",
      "Epoch 9 Batch 200 Loss 3.9768 Accuracy 0.2245\n",
      "Epoch 9 Batch 400 Loss 3.9590 Accuracy 0.2274\n",
      "Epoch 9 Batch 600 Loss 3.9385 Accuracy 0.2303\n",
      "Epoch 9 Batch 800 Loss 3.9250 Accuracy 0.2332\n",
      "Epoch 9 Loss 3.9120 Accuracy 0.2360\n",
      "Time taken for 1 epoch: 3492.8956139087677 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 4.2075 Accuracy 0.2360\n",
      "Epoch 10 Batch 200 Loss 3.8259 Accuracy 0.2388\n",
      "Epoch 10 Batch 400 Loss 3.8181 Accuracy 0.2414\n",
      "Epoch 10 Batch 600 Loss 3.8006 Accuracy 0.2442\n",
      "Epoch 10 Batch 800 Loss 3.7913 Accuracy 0.2468\n",
      "Saving checkpoint for epoch 10 at checkpoints/ckpt-2\n",
      "Epoch 10 Loss 3.7813 Accuracy 0.2494\n",
      "Time taken for 1 epoch: 4187.6405420303345 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        if batch % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "   \n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf238a3",
   "metadata": {},
   "source": [
    "The training is finally over. Lets evaluate the model and translate some sentences from English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c85ab1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(text):\n",
    "    text = eng_tokenizer.texts_to_sequences([text])\n",
    "    text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=ENCODER_LEN, \n",
    "                                                                   padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(text[0], 0)\n",
    "\n",
    "    decoder_input = [hind_tokenizer.word_index['<sos>']]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(DECODER_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == hind_tokenizer.word_index['<eos>']:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afe61cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(eng_text):\n",
    "    hind_text = evaluate(text=eng_text)[0].numpy()\n",
    "    hind_text = np.expand_dims(hind_text[1:], 0)  \n",
    "    return hind_tokenizer.sequences_to_texts(hind_text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c354bbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तो हम इस तरह से देख सकते हैं'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Let's see if the model can understand this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e17d3",
   "metadata": {},
   "source": [
    "Daymm! That does work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ee2e9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'हम मेरे पास आधी रात के पानी की परवाह नहीं करते'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I ate food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3e993e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(\"/Users/meghnahavalgi/Desktop/Neural Modelling/Assignment8/transformer10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a3b51a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मेरे पास एक परिवार है'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"There is a cat in my house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "df68b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'और बहुत ही अच्छे से सीखते हैं'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"There is so much to learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01c9ba",
   "metadata": {},
   "source": [
    "## Conclusion : \n",
    "We have put together a transformer madel to demonstrate translation between two languages by following many steps. Some of the most important learning from this model was,\n",
    "- Encoder - Decoder architecture\n",
    "- concept of why LLM takes long hours to train\n",
    "- Positional encoding\n",
    "- Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717b31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5dc2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645e207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0b4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d8e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1980a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dd877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7520dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931c7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba344b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705dad53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf4e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1dbfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc56a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
